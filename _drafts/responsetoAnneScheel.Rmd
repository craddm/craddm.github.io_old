---
title: "Untitled"
author: "Matt Craddock"
date: "11 March 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Some quick thoughts, not meant as a defense but as a little clarification:

Benedikt already highlighted the reference issue here.  HHO5 probably went for an average reference because they had 62 electrodes and good scalp coverage. Average ref wasn't really an option for the later studies, as average reference is much less justifiable with sparse electrode arrays that provide less coverage - the other three studies only have 19-23 electrodes. It's also perfectly possible that components can change polarity with different references (e.g. see a great paper from 1998 by Jospeh Dien - https://link.springer.com/article/10.3758/BF03209414). Referencing is done timepoint by timepoint, so for each timepoint the data across the whole scalp is shifted up or down by a constant. This can have quite dramatic effects on the waveforms at individual electrodes. Typically when comparing avg reffed data versus linked/average mastoid reffed data, I see more extremes with the mastoid reffed data - peaks tend to be higher, troughs tend to be deeper - but that doesn't necessarily hold generally (i Just tried it on a few datasets and usually going from avg to mastoid shifted the whole topography negative). But in any case it's very difficult to directly compare results across different references. all that said the biggest problem here is probably the tiny sample size in HH05. Another point might be that the N170 - at least  in adults, don't know about babies - is usually biggest in areas close to the mastoids. This can make mastoids a poor choice of reference for the N170 as components physically closer to the reference point tend to be reduced in size.

Lateralization - (relatively) early visual components like the P1 or N1(70) tend to have bilateral topographies; my impression is that people often throw laterality into the mix without a clear hypothesis  or reason to suppose that lateral differences might occur in their specific paradigm. I suspect it is often thrown in in case a reviewer says "were there any differences across hemispheres?", as this is the kind of pat question you might be asked and it saves you the time of putting it in later. That said there are documented lateral differences in face/word recognition, for example, and things like spatial attention also modulate laterality of effects, so it is not completely mad to check for such things. interactions between experimental condition and electrode sites in general can be hard to interpret though, as a significant interaction does not necessarily imply that the underlying neural generators are different across conditions - it can be the same neural generator outputting a different amplitude signal.

Don't understand the use of 100ms post-stimulus as part of the baseline in RHLS08 at all - I don't know why you would do that. I am not sure it is a massive problem for interpreting the results within the study, as assuming it's done how I would imagine, it shifts the ERPs around by a constant and thus doesn't change the relative difference between them at a given time-point. But a very odd choice anyway.

A few words about variability in electrode sites and time-windows; something to keep in mind is that you are rarely interested in sites and time-windows per se, but the underlying signals i.e. you are interested in the N170, which is typically observed over bilateral parieto-occipital regions somewhere between ~160-200 ms. Not all EEG caps follow the 10-10/20 system - for example Biosemi 64 channel caps do, but 128 channel caps do not. Doesn't mean you can't study the N170 with the 128 channel caps because they don't have a P9 or P10 electrode or whatever ones you want to choose. In addition even these 10-10/20 labels can be misleading - they are positions on an sphere, which a head most certainly is not. People have different shaped heads and different shaped brains, so while the electrode positions are similar across conditions, they won't be exact and won't necessarily record activity from the same brain region in the same way. The caps themselves tend also to stretch a bit out of shape over time and use. Of course you can use a Polhemus or something to record exact electrode positions, but you still run into the issue of people have slightly different shaped brains/heads. This is less of an issue with broadly distributed components (e.g. N400, P300), but shorter, more focal components (like N170) in particular can suffer from this. Often when people have the option they will take a cluster of electrodes over a region and average over those, so that typically you're likely to sort of pull-in people who have slightly off-centre components. thus, charitably, you might see variation that is related to the age/stretchiness of the caps, variability. I think people tend not to worry an awful lot as long as the electrodes and selected timepoints are not completely weird or egregiously unusual like 

Another pat question people tend to ask to try to head off reviewers is: how do you know the difference you observe in component X is not just because of differences in earlier component Y?